{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/local/softwares/anaconda3/envs/psycnet/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/data/local/softwares/anaconda3/envs/psycnet/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/data/local/softwares/anaconda3/envs/psycnet/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/data/local/softwares/anaconda3/envs/psycnet/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/data/local/softwares/anaconda3/envs/psycnet/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path as osp\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from nilearn import datasets\n",
    "from nilearn.input_data import NiftiLabelsMasker\n",
    "from nilearn import plotting\n",
    "from nilearn import image\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subjectinfo(data_dir='/data_remote/ABIDE/', file='Phenotypic'):\n",
    "    \"\"\"\n",
    "    :param file: csv file containing subject information\n",
    "    :return: dictionary with relevant key/value pairs\n",
    "    \"\"\"\n",
    "\n",
    "    COI_ABIDEI = ['SITE_ID', 'SUB_ID', 'DX_GROUP', 'AGE_AT_SCAN', 'SEX']\n",
    "    COI_ABIDEII = ['SITE_ID', 'SUB_ID', 'DX_GROUP', 'AGE_AT_SCAN ', 'SEX'] # Notice space after AGE_AT_SCAN\n",
    "\n",
    "    pheno_file = file + \"_ABIDE_I.csv\"\n",
    "    pheno_ABIDEI = pd.read_csv(osp.join(data_dir, pheno_file), \n",
    "                               dtype={'SITE_ID':str, 'SUB_ID':int, 'DX_GROUP':int, 'AGE_AT_SCAN':float, 'SEX':str})[COI_ABIDEI]\n",
    "    pheno_ABIDEI['ABIDE_I_or_II'] = pd.Series(np.ones(len(pheno_ABIDEI))).astype(int)\n",
    "\n",
    "    pheno_file = file + \"_ABIDE_II.csv\"\n",
    "    pheno_ABIDEII = pd.read_csv(osp.join(data_dir, pheno_file), encoding='cp1252',\n",
    "                               dtype={'SITE_ID':str, 'SUB_ID':int, 'DX_GROUP':int, 'AGE_AT_SCAN':float, 'SEX':int})[COI_ABIDEII]\n",
    "    pheno_ABIDEII['ABIDE_I_or_II'] = pd.Series(2*np.ones(len(pheno_ABIDEII))).astype(int)\n",
    "\n",
    "    pheno_ABIDEII.rename(columns = {'AGE_AT_SCAN ':'AGE_AT_SCAN'}, inplace=True) # change column name to take out stupid space   \n",
    "    \n",
    "    pheno = pd.concat([pheno_ABIDEI, pheno_ABIDEII], ignore_index=True)\n",
    "    pheno['DX_GROUP'] = pheno['DX_GROUP']-1 # so that 0-> ASD, 1->CON\n",
    "    \n",
    "    return pheno\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a csv file (Pandas Dataframe) for further machine learning\n",
    "\n",
    "def create_ml_csv(T1_file=None, \n",
    "                  nuisance_file='RS_denoise/nuisance_mat_18', \n",
    "                  img_file='RS_denoise/RS_clean_bptf_MNI.nii.gz',\n",
    "                  input_root_dir='/data_local/deeplearning/ABIDE_LC',\n",
    "                  output_root_dir='/data_local/deeplearning/ABIDE_ML_inputs',\n",
    "                  time_course_dir = 'tc',\n",
    "                  subject_list_file='list_2169'):\n",
    "    \n",
    "    '''\n",
    "    subject_list_file: a file with a list of subject ids\n",
    "    root_dir: root directory with imaging and nuisance data\n",
    "    img_file: rsfmri file\n",
    "    T1_file: T1 scan file\n",
    "    nuisance_file: confounds (motion etc.,)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    subject_list = pd.read_csv(osp.join(input_root_dir, subject_list_file), names=['SUB_ID'], header=None)\n",
    "    subject_info = get_subjectinfo()\n",
    "    \n",
    "    df_data_info = subject_info.merge(subject_list, on='SUB_ID')\n",
    "    df_data_info['SUB_ID'] = np.loadtxt(osp.join(input_root_dir, subject_list_file), dtype='str') # easier to get '00' prefix\n",
    "    #data_columns = ['ids', 'labels', 'tr', 'rsfmri', 't1', 'nuisance']\n",
    "    \n",
    "    rsfmri_file_list = []\n",
    "    nuisance_file_list = []\n",
    "    TR_list = []\n",
    "    nT_list = []\n",
    "    \n",
    "    #outputs\n",
    "    tc_file_list = [] # time course filenames\n",
    "    cc_file_list = [] # correlation matrix filenames\n",
    "    \n",
    "    # Check if output directory exists\n",
    "    if not osp.exists(output_root_dir):\n",
    "        os.makedirs(output_root_dir)\n",
    "        \n",
    "    \n",
    "    for sub_i in df_data_info['SUB_ID']:\n",
    "        rsfmri_file = osp.join(input_root_dir, 'raw', sub_i, img_file)\n",
    "        \n",
    "        hdr = nib.load(rsfmri_file).header\n",
    "        \n",
    "        TR_list.append(hdr.get_zooms()[3])\n",
    "        nT_list.append(hdr.get_data_shape()[3])\n",
    "        rsfmri_file_list.append(rsfmri_file)\n",
    "        nuisance_file_list.append(osp.join(input_root_dir, 'raw', sub_i, nuisance_file))\n",
    "        \n",
    "        #outputs ATLAS->generic name that is a placeholder\n",
    "        tc_file_list.append(osp.join(output_root_dir, sub_i, time_course_dir, 'ATLAS/timecourse.csv'))\n",
    "        cc_file_list.append(osp.join(output_root_dir, sub_i, time_course_dir, 'ATLAS/corr_vec.npy'))\n",
    "\n",
    "\n",
    "    df_data_info['RSFMRI_file'] = rsfmri_file_list\n",
    "    df_data_info['TR'] = TR_list\n",
    "    df_data_info['nTimes'] = nT_list\n",
    "    df_data_info['nuisance_file'] = nuisance_file_list\n",
    "    \n",
    "    df_data_info['tc_file'] = tc_file_list\n",
    "    df_data_info['corr_file'] = cc_file_list\n",
    "    \n",
    "    return df_data_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_atlas(atlas_name, atlas_dir='/data/rmthomas/nilearn_data'): # HO_cort_maxprob_thr25-2mm\n",
    "\n",
    "    # Choose one of the atlases (add more when necessary)\n",
    "    # 1. AAL\n",
    "    # 2. HO_cort_maxprob_thr25-2mm\n",
    "\n",
    "\n",
    "    # Check if valid atlas name\n",
    "    if atlas_name not in ['AAL', 'HO_cort_maxprob_thr25-2mm', 'schaefer_100', 'schaefer_400']:\n",
    "        raise ValueError('atlas_name not found')\n",
    "\n",
    "    if atlas_name == 'AAL':\n",
    "        dataset = datasets.fetch_atlas_aal(version='SPM12')\n",
    "        atlas_filename = dataset.maps\n",
    "        labels = dataset.labels\n",
    "        \n",
    "    if atlas_name == 'HO_cort_maxprob_thr25-2mm':\n",
    "        dataset = datasets.fetch_atlas_harvard_oxford('cort-maxprob-thr25-2mm')\n",
    "        atlas_filename = dataset.maps\n",
    "        labels = dataset.labels[1:] # the first element is background\n",
    "        \n",
    "        \n",
    "    if atlas_name == 'schaefer_100':\n",
    "        atlas_filename = osp.join(atlas_dir,'schaefer/Schaefer2018_100Parcels_17Networks_order_FSLMNI152_2mm.nii')\n",
    "        labels = pd.read_csv(osp.join(atlas_dir, \n",
    "                                           'schaefer/Schaefer2018_100Parcels_17Networks_table.csv'))['label']\n",
    "    if atlas_name == 'schaefer_400':\n",
    "        atlas_filename = osp.join(atlas_dir, \n",
    "                                       'schaefer/Schaefer2018_400Parcels_17Networks_order_FSLMNI152_2mm.nii')\n",
    "        labels = pd.read_csv(osp.join(atlas_dir, \n",
    "                                           'schaefer/Schaefer2018_400Parcels_17Networks_table.csv'))['label']\n",
    "        \n",
    "\n",
    "    return  atlas_filename, labels, len(labels)\n",
    "    #plotting.plot_roi(atlas_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpass(atlas_filename, to_bandpass = False, tr=1.0, low_freq=0.01, high_freq=0.001):\n",
    "    if to_bandpass:\n",
    "        masker = NiftiLabelsMasker(labels_img=atlas_filename, standardize=True, t_r=tr, low_pass=low_freq, high_pass=high_freq)\n",
    "    else:\n",
    "        masker = NiftiLabelsMasker(labels_img=atlas_filename, standardize=True)\n",
    "        \n",
    "    return masker\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tc_corr(atlas_names=['AAL', 'schaefer_100', 'HO_cort_maxprob_thr25-2mm', 'schaefer_400'],\n",
    "                    output_root_dir='/data_local/deeplearning/ABIDE_ML_inputs',\n",
    "                    time_course_dir = 'tc',\n",
    "                    to_bandpass=False):\n",
    "\n",
    "    \n",
    "    df_data_info = create_ml_csv()\n",
    "    \n",
    "    # Write the generic input and output csv files\n",
    "    df_data_info.to_csv(osp.join(output_root_dir, 'data_info.csv'))\n",
    "    \n",
    "    \n",
    "    connectivity_measure = ConnectivityMeasure(kind='correlation')\n",
    "\n",
    "    \n",
    "    nsubjects = len(df_data_info)\n",
    "    \n",
    "    print_counter = 0\n",
    "    for sub_i in df_data_info.index:\n",
    "\n",
    "        \n",
    "        if print_counter%100 == 0:\n",
    "            print(f'{sub_i}/{nsubjects}')\n",
    "        nuisance = pd.read_csv(df_data_info['nuisance_file'].loc[sub_i], sep='\\t', header=None)\n",
    "        nuisance.to_csv('temp_nuisance.csv') # required for the next step in csv format\n",
    "\n",
    "        for atlas_name in atlas_names:\n",
    "            \n",
    "            atlas_filename, labels, nrois = select_atlas(atlas_name)\n",
    "            \n",
    "            if to_bandpass:\n",
    "                    masker = bandpass(atlas_filename, to_bandpass=to_bandpass, tr=df_data_info['TR'].loc[sub_i])\n",
    "            else:\n",
    "                    masker = bandpass(atlas_filename, to_bandpass=to_bandpass)\n",
    "\n",
    "            timecourse = masker.fit_transform(imgs=df_data_info['RSFMRI_file'].loc[sub_i], \n",
    "                                              confounds='temp_nuisance.csv')\n",
    "\n",
    "\n",
    "            cc = connectivity_measure.fit_transform([timecourse])[0]\n",
    "\n",
    "            tc_dir = osp.join(output_root_dir, df_data_info['SUB_ID'].loc[sub_i], \n",
    "                              time_course_dir, atlas_name )\n",
    "            if not osp.exists(tc_dir):\n",
    "                os.makedirs(tc_dir)\n",
    "\n",
    "            # Write timeseries as csv file\n",
    "            tc_file = df_data_info['tc_file'].loc[sub_i].replace('ATLAS', atlas_name)\n",
    "            pd.DataFrame(data=timecourse, columns=labels).to_csv(tc_file)\n",
    "\n",
    "            # Write correlation matrix\n",
    "            corr_file = df_data_info['corr_file'].loc[sub_i].replace('ATLAS', atlas_name)\n",
    "            cc_triu_ids = np.triu_indices(nrois)\n",
    "            np.save(corr_file, cc[cc_triu_ids]) # get only upper triangular\n",
    "\n",
    "        print_counter += 1\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/2169\n",
      "25/2169\n",
      "50/2169\n",
      "75/2169\n",
      "100/2169\n",
      "125/2169\n",
      "150/2169\n",
      "175/2169\n",
      "200/2169\n",
      "225/2169\n",
      "250/2169\n",
      "275/2169\n",
      "300/2169\n",
      "325/2169\n",
      "350/2169\n",
      "375/2169\n",
      "400/2169\n",
      "425/2169\n",
      "450/2169\n",
      "475/2169\n",
      "500/2169\n",
      "525/2169\n",
      "550/2169\n",
      "575/2169\n",
      "600/2169\n",
      "625/2169\n",
      "650/2169\n",
      "675/2169\n",
      "700/2169\n",
      "725/2169\n",
      "750/2169\n",
      "775/2169\n",
      "800/2169\n",
      "825/2169\n",
      "850/2169\n",
      "875/2169\n",
      "900/2169\n",
      "925/2169\n",
      "950/2169\n"
     ]
    }
   ],
   "source": [
    "extract_tc_corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx=datasets.fetch_atlas_harvard_oxford('cort-maxprob-thr25-2mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data exploration\n",
    "\n",
    "df = create_ml_csv()\n",
    "# plot ntimes to check what to include\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,10))\n",
    "df.hist(column='nTimes', bins=[50, 100, 125, 150, 200, 300, 500, 1000], ax=axes[0])\n",
    "df.hist(column='nTimes', cumulative=-1, bins=[50, 100, 125, 150, 200, 300, 1000], linewidth=5, histtype='step', ax=axes[1])\n",
    "#df_input_data['nTimes'].plot.kde()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
